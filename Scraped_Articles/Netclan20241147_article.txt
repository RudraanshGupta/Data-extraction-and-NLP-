


Home  Our Success Stories  Real Estate Data Warehouse



Our Success StoriesInfrastructure & Real EstateIT Real Estate Data Warehouse

By Ajay Bidyarthy -   September 4, 2021 4885 














Client BackgroundClient: A leading Real Estate firm in the EUIndustry Type:  Real EstateServices: Real EstateOrganization Size: 1000+Project ObjectiveThe objective of this project is to build a data warehouse from a website given search and filter criteria.Project DescriptionThe objective of this project is to collect data from a website given search and filter criteria.Data Brief:Crawl all the information for the property adverts once a week and store them in a database. Data language: EnglishFilters:Federal StatesContains a list of the federal states in Germany to Crawl:https://en.wikipedia.org/wiki/States_of_GermanyCategories to CrawlMieten WohnungKaufen WohnungKaufen AnlageobjekteKaufen GrundstückOur SolutionWe have developed a Python tool that crawls and scrapes all the apartment listings for all the states in Germany under each category namely: mieten wohnungen, kaufen wohnungen, kaufen anlageobjekte and kaufen grundstuck. The Scrapy library has been used to crawl and scrape. Beautiful soup could have also been used for the scraping purpose, but for the sake of consistency, Scrapy has been used for both purposes.Scrapy is an application framework for crawling web sites and extracting structured data which can be used for a wide range of useful applications, like data mining, information processing or historical archival.Even though Scrapy was originally designed for web scraping, it can also be used to extract data using APIs (such as Amazon Associates Web Services) or as a general purpose web crawler.Four Spiders have been created for each category to be scraped. Every spider crawls all the states in Germany and scrapes all the apartment listings for important data. Every spider creates a separate JSON file to store all its data. This data is then converted to CSV using another python script called “conversion”.The python tool has been completely automated and only needs the “Controller” script to be run. The script also has the capability of running every two weeks automatically. Project DeliverablesFour CSV files (one for each category):Mieten Wohnungen.csvKaufen Wohnungen.csvKaufen Anlageobjekte.csvKaufen Grundstuck.csvLanguage/techniques usedPythonWeb Crawling & ScrapingSkills usedData ScrapingData CrawlingAdvanced Python programmingProject Snapshots 



Previous articleTraction Dashboards of Marketing Campaigns and PostsNext articleDatawarehouse, and Recommendations Engine for AirBNB Ajay Bidyarthy  
RELATED ARTICLESMORE FROM AUTHOR




 

Facial Recognition Attendance System 

 



 

Face Recognition Using DeepFace 

 



 

AI and ML-Based YouTube Analytics and Content Creation Tool for Optimizing Subscriber Engagement and Content Strategy 

  

 




MOST POPULAR INSIGHTS




Chatbot and conversation agent Transform the experience and engagement 
June 12, 2019 


 




How Big Data Will Impact the Future of Business? 
July 20, 2021 


 




AWS QuickSight Reporting Dashboard 
January 16, 2022 


 




Impact of COVID-19 on Engineering and Medical College during this pandemic... 
December 7, 2021 


 Load more RECOMMENDED INSIGHTS



 
Securing Sensitive Financial Data with Privacy-Preserving Machine Learning for Predictive Analytics

 



 
SEO Tool – AI and Data Driven

 



 
The Future of Telehealth Services

 



 
The rise of the OTT platform and its impact on the...

   

 
 
